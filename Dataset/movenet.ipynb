{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow-hub) (5.29.3)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\lvcm3\\AppData\\Local\\Temp\\pip-req-build-guut5bit'\n",
      "  error: RPC failed; curl 56 Recv failure: Connection was reset\n",
      "  error: 8822 bytes of body are still expected\n",
      "  fetch-pack: unexpected disconnect while reading sideband packet\n",
      "  fatal: early EOF\n",
      "  fatal: fetch-pack: invalid index-pack output\n",
      "  fatal: could not fetch 3ae87b238e001dd59d042826be8ce7b3c44fbfbd from promisor remote\n",
      "  warning: Clone succeeded, but checkout failed.\n",
      "  You can inspect what was checked out with 'git status'\n",
      "  and retry with 'git restore --source=HEAD :/'\n",
      "\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\lvcm3\\AppData\\Local\\Temp\\pip-req-build-guut5bit' did not run successfully.\n",
      "  │ exit code: 128\n",
      "  ╰─> See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\lvcm3\\AppData\\Local\\Temp\\pip-req-build-guut5bit' did not run successfully.\n",
      "│ exit code: 128\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\lvcm3\\appdata\\local\\temp\\pip-req-build-guut5bit\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow-hub\n",
    "%pip install git+https://github.com/tensorflow/docs\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (2.37.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from imageio) (2.1.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from imageio) (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps from joint names to keypoint indices.\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'left_eye': 1,\n",
    "    'right_eye': 2,\n",
    "    'left_ear': 3,\n",
    "    'right_ear': 4,\n",
    "    'left_shoulder': 5,\n",
    "    'right_shoulder': 6,\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_wrist': 9,\n",
    "    'right_wrist': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_ankle': 15,\n",
    "    'right_ankle': 16\n",
    "}\n",
    "\n",
    "# Maps bones to a matplotlib color name.\n",
    "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "def _keypoints_and_edges_for_display(keypoints_with_scores,\n",
    "                                     height,\n",
    "                                     width,\n",
    "                                     keypoint_threshold=0.11):\n",
    "  \"\"\"Returns high confidence keypoints and edges for visualization.\n",
    "\n",
    "  Args:\n",
    "    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n",
    "      the keypoint coordinates and scores returned from the MoveNet model.\n",
    "    height: height of the image in pixels.\n",
    "    width: width of the image in pixels.\n",
    "    keypoint_threshold: minimum confidence score for a keypoint to be\n",
    "      visualized.\n",
    "\n",
    "  Returns:\n",
    "    A (keypoints_xy, edges_xy, edge_colors) containing:\n",
    "      * the coordinates of all keypoints of all detected entities;\n",
    "      * the coordinates of all skeleton edges of all detected entities;\n",
    "      * the colors in which the edges should be plotted.\n",
    "  \"\"\"\n",
    "  keypoints_all = []\n",
    "  keypoint_edges_all = []\n",
    "  edge_colors = []\n",
    "  num_instances, _, _, _ = keypoints_with_scores.shape\n",
    "  for idx in range(num_instances):\n",
    "    kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
    "    kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
    "    kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
    "    kpts_absolute_xy = np.stack(\n",
    "        [width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
    "    kpts_above_thresh_absolute = kpts_absolute_xy[\n",
    "        kpts_scores > keypoint_threshold, :]\n",
    "    keypoints_all.append(kpts_above_thresh_absolute)\n",
    "\n",
    "    for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n",
    "      if (kpts_scores[edge_pair[0]] > keypoint_threshold and\n",
    "          kpts_scores[edge_pair[1]] > keypoint_threshold):\n",
    "        x_start = kpts_absolute_xy[edge_pair[0], 0]\n",
    "        y_start = kpts_absolute_xy[edge_pair[0], 1]\n",
    "        x_end = kpts_absolute_xy[edge_pair[1], 0]\n",
    "        y_end = kpts_absolute_xy[edge_pair[1], 1]\n",
    "        line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "        keypoint_edges_all.append(line_seg)\n",
    "        edge_colors.append(color)\n",
    "  if keypoints_all:\n",
    "    keypoints_xy = np.concatenate(keypoints_all, axis=0)\n",
    "  else:\n",
    "    keypoints_xy = np.zeros((0, 17, 2))\n",
    "\n",
    "  if keypoint_edges_all:\n",
    "    edges_xy = np.stack(keypoint_edges_all, axis=0)\n",
    "  else:\n",
    "    edges_xy = np.zeros((0, 2, 2))\n",
    "  return keypoints_xy, edges_xy, edge_colors\n",
    "\n",
    "\n",
    "def draw_prediction_on_image(\n",
    "    image, keypoints_with_scores, crop_region=None, close_figure=False,\n",
    "    output_image_height=None):\n",
    "  \"\"\"Draws the keypoint predictions on image.\n",
    "\n",
    "  Args:\n",
    "    image: A numpy array with shape [height, width, channel] representing the\n",
    "      pixel values of the input image.\n",
    "    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n",
    "      the keypoint coordinates and scores returned from the MoveNet model.\n",
    "    crop_region: A dictionary that defines the coordinates of the bounding box\n",
    "      of the crop region in normalized coordinates (see the init_crop_region\n",
    "      function below for more detail). If provided, this function will also\n",
    "      draw the bounding box on the image.\n",
    "    output_image_height: An integer indicating the height of the output image.\n",
    "      Note that the image aspect ratio will be the same as the input image.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array with shape [out_height, out_width, channel] representing the\n",
    "    image overlaid with keypoint predictions.\n",
    "  \"\"\"\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  # To remove the huge white borders\n",
    "  fig.tight_layout(pad=0)\n",
    "  ax.margins(0)\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticklabels([])\n",
    "  plt.axis('off')\n",
    "\n",
    "  im = ax.imshow(image)\n",
    "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
    "  ax.add_collection(line_segments)\n",
    "  # Turn off tick labels\n",
    "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
    "\n",
    "  (keypoint_locs, keypoint_edges,\n",
    "   edge_colors) = _keypoints_and_edges_for_display(\n",
    "       keypoints_with_scores, height, width)\n",
    "\n",
    "  line_segments.set_segments(keypoint_edges)\n",
    "  line_segments.set_color(edge_colors)\n",
    "  if keypoint_edges.shape[0]:\n",
    "    line_segments.set_segments(keypoint_edges)\n",
    "    line_segments.set_color(edge_colors)\n",
    "  if keypoint_locs.shape[0]:\n",
    "    scat.set_offsets(keypoint_locs)\n",
    "\n",
    "  if crop_region is not None:\n",
    "    xmin = max(crop_region['x_min'] * width, 0.0)\n",
    "    ymin = max(crop_region['y_min'] * height, 0.0)\n",
    "    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
    "    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin,ymin),rec_width,rec_height,\n",
    "        linewidth=1,edgecolor='b',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "  fig.canvas.draw()\n",
    "  image_from_plot = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "  image_from_plot = image_from_plot.reshape(\n",
    "      fig.canvas.get_width_height()[::-1] + (4,))\n",
    "  image_from_plot = image_from_plot[:, :, :3]\n",
    "  plt.close(fig)\n",
    "  if output_image_height is not None:\n",
    "    output_image_width = int(output_image_height / height * width)\n",
    "    image_from_plot = cv2.resize(\n",
    "        image_from_plot, dsize=(output_image_width, output_image_height),\n",
    "         interpolation=cv2.INTER_CUBIC)\n",
    "  return image_from_plot\n",
    "\n",
    "def progress(value, max=100):\n",
    "  return HTML(\"\"\"\n",
    "      <progress\n",
    "          value='{value}'\n",
    "          max='{max}',\n",
    "          style='width: 100%'\n",
    "      >\n",
    "          {value}\n",
    "      </progress>\n",
    "  \"\"\".format(value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"movenet_thunder\"\n",
    "\n",
    "if \"tflite\" in model_name:\n",
    "  if \"movenet_lightning_f16\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4?lite-format=tflite\n",
    "    input_size = 192\n",
    "  elif \"movenet_thunder_f16\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n",
    "    input_size = 256\n",
    "  elif \"movenet_lightning_int8\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/int8/4?lite-format=tflite\n",
    "    input_size = 192\n",
    "  elif \"movenet_thunder_int8\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/int8/4?lite-format=tflite\n",
    "    input_size = 256\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported model name: %s\" % model_name)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  def movenet(input_image):\n",
    "    \"\"\"Runs detection on an input image.\n",
    "\n",
    "    Args:\n",
    "      input_image: A [1, height, width, 3] tensor represents the input image\n",
    "        pixels. Note that the height/width should already be resized and match the\n",
    "        expected input resolution of the model before passing into this function.\n",
    "\n",
    "    Returns:\n",
    "      A [1, 1, 17, 3] float numpy array representing the predicted keypoint\n",
    "      coordinates and scores.\n",
    "    \"\"\"\n",
    "    # TF Lite format expects tensor type of uint8.\n",
    "    input_image = tf.cast(input_image, dtype=tf.uint8)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_image.numpy())\n",
    "    # Invoke inference.\n",
    "    interpreter.invoke()\n",
    "    # Get the model prediction.\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return keypoints_with_scores\n",
    "\n",
    "else:\n",
    "  if \"movenet_lightning\" in model_name:\n",
    "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "    input_size = 192\n",
    "  elif \"movenet_thunder\" in model_name:\n",
    "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "    input_size = 256\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported model name: %s\" % model_name)\n",
    "\n",
    "  def movenet(input_image):\n",
    "    \"\"\"Runs detection on an input image.\n",
    "\n",
    "    Args:\n",
    "      input_image: A [1, height, width, 3] tensor represents the input image\n",
    "        pixels. Note that the height/width should already be resized and match the\n",
    "        expected input resolution of the model before passing into this function.\n",
    "\n",
    "    Returns:\n",
    "      A [1, 1, 17, 3] float numpy array representing the predicted keypoint\n",
    "      coordinates and scores.\n",
    "    \"\"\"\n",
    "    model = module.signatures['serving_default']\n",
    "\n",
    "    # SavedModel format expects tensor type of int32.\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    # Run model inference.\n",
    "    outputs = model(input_image)\n",
    "    # Output is a [1, 1, 17, 3] tensor.\n",
    "    keypoints_with_scores = outputs['output_0'].numpy()\n",
    "    return keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movenet(image_path):\n",
    "    # Load the input image.\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "\n",
    "    # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "    input_image = tf.expand_dims(image, axis=0)\n",
    "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "\n",
    "    # Run model inference.\n",
    "    keypoints_with_scores = movenet(input_image)\n",
    "    \n",
    "    return keypoints_with_scores\n",
    "\n",
    "def visualize_movenet(keypoints_with_scores, image_path,  output_path):\n",
    "    \n",
    "    # Load the input image.\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    \n",
    "    # Visualize the predictions with image.\n",
    "    display_image = tf.expand_dims(image, axis=0)\n",
    "    display_image = tf.cast(tf.image.resize_with_pad(\n",
    "        display_image, 1280, 1280), dtype=tf.int32)\n",
    "    output_overlay = draw_prediction_on_image(\n",
    "        np.squeeze(display_image.numpy(), axis=0), keypoints_with_scores)\n",
    "\n",
    "    # plt.figure(figsize=(5, 5))\n",
    "    # plt.imshow(output_overlay)\n",
    "    # _ = plt.axis('off')\n",
    "\n",
    "    # Save the overlay\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(output_overlay, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hip_center(keypoints_with_scores):\n",
    "    \n",
    "    # Get all keypoints\n",
    "    keypoints = keypoints_with_scores[0, 0, :, :2]  # shape: (17, 2)\n",
    "    scores = keypoints_with_scores[0, 0, :, 2]      # Confidence scores\n",
    "    \n",
    "    confidence_threshold = 0.11\n",
    "    \n",
    "    # Get center of body (hip)\n",
    "    left_hip = keypoints[11]\n",
    "    right_hip = keypoints[12]\n",
    "    \n",
    "    # Get the hip center (if confidence > threshold)\n",
    "    if scores[11] > confidence_threshold and scores[12] > confidence_threshold :\n",
    "        hip_center = (left_hip + right_hip) / 2\n",
    "    elif scores[11] > confidence_threshold:\n",
    "        hip_center = left_hip\n",
    "    elif scores[12] > confidence_threshold:\n",
    "        hip_center = right_hip\n",
    "    else:\n",
    "        # Fallback: use the mean of all the keypoints\n",
    "        valid_indices = np.where(scores > confidence_threshold)[0]\n",
    "        hip_center = np.mean(keypoints[valid_indices], axis=0) if len(valid_indices) > 0 else np.zeros(2)\n",
    "    \n",
    "    # Change the keypoints to hip oriented\n",
    "    keypoints_centered = keypoints - hip_center\n",
    "    \n",
    "    # Height estimation from shoulder to hip\n",
    "    left_shoulder = keypoints[5]\n",
    "    right_shoulder = keypoints[6]\n",
    "    \n",
    "    # Normalization with height estimation (if confidence > threshold)\n",
    "    if scores[5] > confidence_threshold and scores[6] > confidence_threshold and np.linalg.norm(left_shoulder - right_shoulder) > 0:\n",
    "        shoulder_center = (left_shoulder + right_shoulder) / 2\n",
    "        body_height = np.linalg.norm(shoulder_center - hip_center)\n",
    "        keypoints_normalized = keypoints_centered / body_height\n",
    "    else:\n",
    "        # Fallback: use a normal case body_height shoulder-to-hip 0.15 - 0.19\n",
    "        keypoints_normalized = keypoints_centered / 0.17\n",
    "    \n",
    "    return keypoints_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From this, the code get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize MoveNet\n",
    "\n",
    "Get all 3 movement (Berdiri, Sujud, Duduk)</br>\n",
    "**_<span style=\"color:cyan\">movement = [\"Berdiri\", \"Sujud\", \"Duduk\"]</span>_**\n",
    "\n",
    "Iteration per movement </br>\n",
    "**_<span style=\"color:cyan\">for j in movement:</span>_**\n",
    "\n",
    "Get data from directory path </br>\n",
    "**_<span style=\"color:cyan\">files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]</span>_**\n",
    "\n",
    "Iteration per data from directory </br>\n",
    "**_<span style=\"color:cyan\">for i, file in enumerate(files, start=1):</span>_**\n",
    "\n",
    "Run MoveNet to save to image </br>\n",
    "**_<span style=\"color:cyan\">visualize_movenet(load_movenet(image_path+str(i-1)+\".jpg\"), image_path+str(i-1)+\".jpg\", final_path+str(i-1)+\".jpg\")</span>_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize MoveNet Raw ##\n",
    "\n",
    "movement = [\"Berdiri\", \"Sujud\", \"Duduk\"]\n",
    "\n",
    "for j in movement:\n",
    "    # Set directory path\n",
    "    directory_path = \"Hasil/data_frame/\"+j\n",
    "    final_path = \"Hasil/final_frame/\"+j+\"/final_\"\n",
    "    image_path = directory_path+\"/frame_\"\n",
    "\n",
    "    # Get all total data in directory path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Iteration per data to movenet\n",
    "    for i, file in enumerate(files, start=1):\n",
    "        visualize_movenet(load_movenet(image_path+str(i-1)+\".jpg\"), image_path+str(i-1)+\".jpg\", final_path+str(i-1)+\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory path\n",
    "path = \"Ruku/hasil/\"\n",
    "directory_path = path+\"data_frame/Berdiri/\"\n",
    "final_path = path+\"final_frame/final_\"\n",
    "image_path = directory_path+\"/frame_\"\n",
    "\n",
    "# Get all total data in directory path\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "# Iteration per data to movenet\n",
    "for i, file in enumerate(files, start=1):\n",
    "    visualize_movenet(load_movenet(image_path+str(i-1)+\".jpg\"), image_path+str(i-1)+\".jpg\", final_path+str(i-1)+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Keypoints Save Fig Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalized Keypoints MoveNet Safe Plot ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "movement = [\"Berdiri\", \"Sujud\", \"Duduk\"]\n",
    "\n",
    "for j in range(len(movement)):\n",
    "    # Set directory path\n",
    "    directory_path = \"Hasil/data_frame/\"+movement[j]\n",
    "    final_path = \"Hasil/final1_frame/\"+movement[j]+\"/final_\"\n",
    "    image_path = directory_path+\"/frame_\"\n",
    "\n",
    "    # Get all total data in directory path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Iteration per data\n",
    "    for i, file in enumerate(files, start=1):\n",
    "\n",
    "        # Get keypoints after normalize from data in directory path\n",
    "        normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\"))\n",
    "\n",
    "        fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        # Setting axis\n",
    "        ax.set_xlim(-2, 2)\n",
    "        ax.set_ylim(-2, 2)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(\"Normalized Pose\")\n",
    "\n",
    "        # Plot titik\n",
    "        for x, y in normalized_keypoints:\n",
    "            plt.plot(y, x, 'ro')  # titik merah\n",
    "\n",
    "        # Sambungkan titik-titik (opsional)\n",
    "        POSE_CONNECTIONS = [\n",
    "            (5, 6), (5, 11), (6, 12),  # shoulders to hips\n",
    "            (5, 7), (7, 9),  # left arm\n",
    "            (6, 8), (8, 10), # right arm\n",
    "            (11, 13), (13, 15),  # left leg\n",
    "            (12, 14), (14, 16),  # right leg\n",
    "            (11, 12), (5, 6)  # hips and shoulders\n",
    "        ]\n",
    "        for a, b in POSE_CONNECTIONS:\n",
    "            x1, y1 = normalized_keypoints[a]\n",
    "            x2, y2 = normalized_keypoints[b]\n",
    "            plt.plot([y1, y2], [x1, x2], 'b-')  # Blue line\n",
    "\n",
    "        # Keep margin\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_path}{i-1}.jpg\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalized Keypoints MoveNet Safe Plot ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set directory path\n",
    "path = \"Ruku/hasil/\"\n",
    "directory_path = path+\"data_frame/Berdiri/\"\n",
    "final_path = path+\"final1_frame/final_\"\n",
    "image_path = directory_path+\"/frame_\"\n",
    "\n",
    "\n",
    "# Get all total data in directory path\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "# Iteration per data\n",
    "for i, file in enumerate(files, start=1):\n",
    "\n",
    "    # Get keypoints after normalize from data in directory path\n",
    "    normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\"))\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Setting axis\n",
    "    ax.set_xlim(-2, 2)\n",
    "    ax.set_ylim(-2, 2)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_title(\"Normalized Pose\")\n",
    "\n",
    "    # Plot titik\n",
    "    for x, y in normalized_keypoints:\n",
    "        plt.plot(y, x, 'ro')  # titik merah\n",
    "\n",
    "    # Sambungkan titik-titik (opsional)\n",
    "    POSE_CONNECTIONS = [\n",
    "        (5, 6), (5, 11), (6, 12),  # shoulders to hips\n",
    "        (5, 7), (7, 9),  # left arm\n",
    "        (6, 8), (8, 10), # right arm\n",
    "        (11, 13), (13, 15),  # left leg\n",
    "        (12, 14), (14, 16),  # right leg\n",
    "        (11, 12), (5, 6)  # hips and shoulders\n",
    "    ]\n",
    "    for a, b in POSE_CONNECTIONS:\n",
    "        x1, y1 = normalized_keypoints[a]\n",
    "        x2, y2 = normalized_keypoints[b]\n",
    "        plt.plot([y1, y2], [x1, x2], 'b-')  # Blue line\n",
    "\n",
    "    # Keep margin\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{final_path}{i-1}.jpg\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Keypoints to CSV\n",
    "\n",
    "Set Dictionary of keypoint</br>\n",
    "\n",
    "Set header of CSV</br>\n",
    "**<span style=\"color:cyan\">\n",
    "header = [] </br>\n",
    "for j in range(len(KEYPOINT_DICT)):</br>\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]</br>\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]</br>\n",
    "</span>**\n",
    "\n",
    "Open CSV file</br>\n",
    "**_<span style=\"color:cyan\">with open(file_output, mode='w', newline='') as file:</span>_**\n",
    "\n",
    "Get flatten keypoints normalize</br>\n",
    "**_<span style=\"color:cyan\">normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\")).flatten()</span>_**\n",
    "\n",
    "Write header & data</br>\n",
    "**_<span style=\"color:cyan\">writer.writerow([h.ljust(column_width) for h in header])</span>_**</br>\n",
    "**_<span style=\"color:cyan\">writer.writerow([h.ljust(column_width) for h in result])</span>_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Normalized Keypoints to CSV ##\n",
    "\n",
    "import csv\n",
    "\n",
    "movement = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "for m in movement:\n",
    "\n",
    "    # Set directory path\n",
    "    directory_path = \"Hasil/data_frame/\"+m\n",
    "    image_path = directory_path+\"/frame_\"\n",
    "\n",
    "    # Get all data from directory path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Set header for CSV file\n",
    "    header = []\n",
    "\n",
    "    for j in range(len(KEYPOINT_DICT)):\n",
    "        header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]\n",
    "        header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]\n",
    "\n",
    "    file_output = \"Hasil/keypoints_\"+m+\".csv\"\n",
    "\n",
    "    # Fix width col\n",
    "    column_width = 12\n",
    "\n",
    "    # Open CSV file\n",
    "    with open(file_output, mode='w', newline='') as file:\n",
    "\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write CSV file header\n",
    "        writer.writerow([h.ljust(column_width) for h in header])\n",
    "\n",
    "        # Iteration per data in directory path\n",
    "        for i, file in enumerate(files, start=1):\n",
    "\n",
    "            # Get flatten normalize keypoints\n",
    "            normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\")).flatten()\n",
    "            result = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "\n",
    "            # Write CSV file data\n",
    "            writer.writerow([h.ljust(column_width) for h in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_output = \"test.csv\"\n",
    "\n",
    "gerakan = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "\n",
    "with open(file_output, mode='w', newline='') as file:\n",
    "\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for j in gerakan:\n",
    "\n",
    "        label = j.ljust(12)\n",
    "\n",
    "        directory_path = \"Test/Frame/\"+j\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "        # Lakukan perulangan sebanyak jumlah file\n",
    "        for i, file in enumerate(files, start=1):\n",
    "            total += 1\n",
    "\n",
    "        for i in range(total):\n",
    "            path = \"Test/Frame/\"+j+\"/frame_\"+str(i)+\".jpg\"\n",
    "\n",
    "            normalized_keypoints = normalize_hip_center(load_movenet(path)).flatten()\n",
    "            data = np.append(normalized_keypoints, label)\n",
    "\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "file_output = \"test2.csv\"\n",
    "\n",
    "gerakan = [\"Berdiri\", \"Duduk\", \"Sujud\", \"Ruku\"]\n",
    "\n",
    "with open(file_output, mode='w', newline='') as file:\n",
    "\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    for j in gerakan:\n",
    "\n",
    "        label = j.ljust(12)\n",
    "\n",
    "        directory_path = \"Test/Frame/Tes/\"+j\n",
    "\n",
    "        total = 0\n",
    "\n",
    "        files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "        # Lakukan perulangan sebanyak jumlah file\n",
    "        for i, file in enumerate(files, start=1):\n",
    "            total += 1\n",
    "\n",
    "        for i in range(total):\n",
    "            path = directory_path+\"/frame_\"+str(i)+\".jpg\"\n",
    "\n",
    "            normalized_keypoints = normalize_hip_center(load_movenet(path)).flatten()\n",
    "            data = np.append(normalized_keypoints, label)\n",
    "\n",
    "            writer.writerow(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints for Person to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Normalized Keypoints to CSV ##\n",
    "\n",
    "import csv\n",
    "\n",
    "movement = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "person = [\"Galileo\", \"Hizkia\", \"Nicholas\", \"Ridwan\", \"Adji\", \"Bill\", \"Khanif\", \"Ruku\", \"Rukuk\"]\n",
    "val = [\"Galileo\", \"Adji\", \"Rukuk\"]\n",
    "# person = [\"Ridwan\", \"Galileo\", \"Ruku\", \"Rukuk\"]\n",
    "# val = [\"Galileo\", \"Rukuk\"]\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "# Set header for CSV file\n",
    "header = []\n",
    "\n",
    "for j in range(len(KEYPOINT_DICT)):\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]\n",
    "header += [\"label\"]\n",
    "\n",
    "# Fix width col\n",
    "column_width = 12\n",
    "\n",
    "file_train = \"Hasil/keypoints_train.csv\"\n",
    "file_val = \"Hasil/keypoints_val.csv\"\n",
    "\n",
    "# Open CSV file\n",
    "with open(file_train, mode='w', newline='') as file:\n",
    "    with open(file_val, mode='w', newline='') as fileVal:\n",
    "\n",
    "        writer1 = csv.writer(fileVal)\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write CSV file header\n",
    "        writer.writerow([h.ljust(column_width) for h in header])\n",
    "        writer1.writerow([h.ljust(column_width) for h in header])\n",
    "\n",
    "        writerTemp = writer\n",
    "\n",
    "        for p in person:\n",
    "\n",
    "            if p in val:\n",
    "                writerTemp = writer1\n",
    "            else:\n",
    "                writerTemp = writer\n",
    "\n",
    "\n",
    "            for m in movement:\n",
    "\n",
    "                # Set directory path\n",
    "                directory_path = p+\"/Hasil/data_frame/\"+m\n",
    "                image_path = directory_path+\"/frame_\"\n",
    "\n",
    "                # Get all data from directory path\n",
    "                files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "                # Iteration per data in directory path\n",
    "                for i, file in enumerate(files, start=1):\n",
    "\n",
    "                    # Get flatten normalize keypoints\n",
    "                    normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\")).flatten()\n",
    "                    result = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "\n",
    "                    if p == \"Ruku\" or p == \"Rukuk\":\n",
    "                        result += [\"Ruku\"]\n",
    "                    else:\n",
    "                        result += [m]\n",
    "\n",
    "                    # Write CSV file data\n",
    "                    writerTemp.writerow([h.ljust(column_width) for h in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join All Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join Keypoints to Final Result\n",
    "\n",
    "import csv\n",
    "\n",
    "movement = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "final = \"Hasil/keypoints.csv\"\n",
    "\n",
    "with open(final, mode='w', newline='') as file :\n",
    "\n",
    "    header_bool = False\n",
    "    write_csv = csv.writer(file)\n",
    "\n",
    "    for i in range(len(movement)):\n",
    "\n",
    "        keypoints = \"Hasil/keypoints_\"+movement[i]+\".csv\"\n",
    "\n",
    "        with open(keypoints, mode='r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            header = next(reader)\n",
    "            header += [\"label\"]\n",
    "            if(not(header_bool)):\n",
    "                write_csv.writerow(header)\n",
    "                header_bool = True\n",
    "\n",
    "            for row in reader:\n",
    "                row = [float(rows) for rows in row]\n",
    "                row += [movement[i]]\n",
    "                write_csv.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Coordinate Real Image vs Augmented Image (Vertically Mirroring)\n",
    "\n",
    "#### Difference between real image & augmented (vertically mirroring) x & x' totally different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nose_y      ', 'nose_x      ', 'l_eye_y     ', 'l_eye_x     ', 'r_eye_y     ', 'r_eye_x     ', 'l_ear_y     ', 'l_ear_x     ', 'r_ear_y     ', 'r_ear_x     ', 'l_shldr_y   ', 'l_shldr_x   ', 'r_shldr_y   ', 'r_shldr_x   ', 'l_elbow_y   ', 'l_elbow_x   ', 'r_elbow_y   ', 'r_elbow_x   ', 'l_wrist_y   ', 'l_wrist_x   ', 'r_wrist_y   ', 'r_wrist_x   ', 'l_hip_y     ', 'l_hip_x     ', 'r_hip_y     ', 'r_hip_x     ', 'l_knee_y    ', 'l_knee_x    ', 'r_knee_y    ', 'r_knee_x    ', 'l_ankle_y   ', 'l_ankle_x   ', 'r_ankle_y   ', 'r_ankle_x   ']\n",
      "['557', '1.318346381 ', '-0.571944416', '1.377509236 ', '-0.605420411', '1.368300319 ', '-0.624004602', '1.280033827 ', '-0.621252596', '1.239267945 ', '-0.710023165', '0.889830530 ', '-0.508243859', '0.765324533 ', '-0.614459693', '0.883359194 ', '0.199855059 ', '0.841187477 ', '-0.239032492', '1.301983953 ', '0.123639010 ', '1.257931828 ', '0.102156200 ', '0.034755234 ', '-0.023501195', '-0.034755550', '0.023501195 ', '0.834784269 ', '0.198331967 ', '0.665311873 ', '0.185980454 ', '0.507609665 ', '0.311661482 ', '0.290738940 ', '0.360784113 ']\n",
      "['1342', '-1.099727988', '0.409966379 ', '-1.197170854', '0.494705498 ', '-1.193386078', '0.328392416 ', '-1.296021819', '0.494780779 ', '-1.305977464', '0.081380136 ', '-1.035103440', '0.481515527 ', '-0.944333255', '-0.195455164', '-0.335489661', '0.627446771 ', '-0.099193260', '-0.168618992', '0.249015003 ', '0.934208989 ', '0.519589186 ', '0.151498184 ', '-0.073964588', '0.271703154 ', '0.073964588 ', '-0.271703154', '0.610375822 ', '0.954915822 ', '0.547214568 ', '0.168938562 ', '0.559911728 ', '0.217740282 ', '0.694793463 ', '0.176104978 ']\n"
     ]
    }
   ],
   "source": [
    "## Check Difference Between Real Image & Augmented ##\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "# Set header to output\n",
    "header = []\n",
    "\n",
    "# Fix width col\n",
    "column_width = 12\n",
    "\n",
    "for j in range(0, 17):\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]\n",
    "\n",
    "print([h.ljust(column_width) for h in header])\n",
    "\n",
    "## Value Check ##\n",
    "gerakan = \"Sujud\"\n",
    "frame = 557\n",
    "\n",
    "# Set directory path\n",
    "directory_path = \"Hasil/data_frame/\"+gerakan\n",
    "image_path = directory_path+\"/frame_\"\n",
    "\n",
    "# Get all data from directory path and total/2\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "total_file = int(len(files)/2)\n",
    "\n",
    "# Image1 normal image get keypoints normalize\n",
    "image_path = \"Hasil/data_frame/\"+gerakan+\"/frame_\"+str(frame)+\".jpg\"\n",
    "normalized_keypoints = normalize_hip_center(load_movenet(image_path)).flatten()\n",
    "hasil = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "\n",
    "print([str(frame)]+[h.ljust(column_width) for h in hasil])\n",
    "\n",
    "# Image2 augmented image get keypoints normalize\n",
    "image_path = \"Hasil/data_frame/Duduk/frame_\"+str(frame+total_file)+\".jpg\"\n",
    "normalized_keypoints = normalize_hip_center(load_movenet(image_path)).flatten()\n",
    "hasil = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "print([str(frame+total_file)]+[h.ljust(column_width) for h in hasil])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.4519771   1.5375944 ]\n",
      " [ 1.310508    1.7543367 ]\n",
      " [ 1.2508988   1.4815772 ]\n",
      " [ 0.44041127  2.0667017 ]\n",
      " [ 0.54595095  1.1721556 ]\n",
      " [-0.07735106  2.0989516 ]\n",
      " [ 0.49106178 -0.14220832]\n",
      " [ 1.2479997   1.4417425 ]\n",
      " [ 1.7054337  -0.22033674]\n",
      " [ 2.6222715   0.9936968 ]\n",
      " [ 3.0781224   0.0404622 ]\n",
      " [-0.27394494  0.5428766 ]\n",
      " [ 0.27394494 -0.5428766 ]\n",
      " [ 2.6148221   1.0093504 ]\n",
      " [ 3.378826    0.0587763 ]\n",
      " [ 4.9422383   1.375368  ]\n",
      " [ 5.7814503   0.40646085]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_path = \"../Ignore/Ruku/hasil/data_frame/frame_1.jpg\"\n",
    "normalized_keypoints = normalize_hip_center(load_movenet(image_path))\n",
    "\n",
    "print(normalized_keypoints)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Setting axis\n",
    "ax.set_xlim(-2, 2)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.set_aspect('equal')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Normalized Pose\")\n",
    "\n",
    "# Plot titik\n",
    "for x, y in normalized_keypoints:\n",
    "    plt.plot(y, x, 'ro')  # titik merah\n",
    "\n",
    "# Sambungkan titik-titik (opsional)\n",
    "POSE_CONNECTIONS = [\n",
    "    (5, 6), (5, 11), (6, 12),  # shoulders to hips\n",
    "    (5, 7), (7, 9),  # left arm\n",
    "    (6, 8), (8, 10), # right arm\n",
    "    (11, 13), (13, 15),  # left leg\n",
    "    (12, 14), (14, 16),  # right leg\n",
    "    (11, 12), (5, 6)  # hips and shoulders\n",
    "]\n",
    "for a, b in POSE_CONNECTIONS:\n",
    "    x1, y1 = normalized_keypoints[a]\n",
    "    x2, y2 = normalized_keypoints[b]\n",
    "    plt.plot([y1, y2], [x1, x2], 'b-')  # garis biru\n",
    "\n",
    "# Jaga margin tetap\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42498848 0.42031005 0.2835869 ]\n",
      "Nose           : x=0.497, y=0.559, score=0.511 ✓\n",
      "Left Eye       : x=0.514, y=0.548, score=0.524 ✓\n",
      "Right Eye      : x=0.493, y=0.543, score=0.583 ✓\n",
      "Left Ear       : x=0.538, y=0.480, score=0.520 ✓\n",
      "Right Ear      : x=0.469, y=0.488, score=0.754 ✓\n",
      "Left Shoulder  : x=0.541, y=0.440, score=0.785 ✓\n",
      "Right Shoulder : x=0.367, y=0.484, score=0.507 ✓\n",
      "Left Elbow     : x=0.490, y=0.543, score=0.818 ✓\n",
      "Right Elbow    : x=0.361, y=0.578, score=0.558 ✓\n",
      "Left Wrist     : x=0.455, y=0.649, score=0.405 ✓\n",
      "Right Wrist    : x=0.381, y=0.684, score=0.434 ✓\n",
      "Left Hip       : x=0.420, y=0.425, score=0.284 ✗\n",
      "Right Hip      : x=0.336, y=0.467, score=0.444 ✓\n",
      "Left Knee      : x=0.456, y=0.649, score=0.359 ✓\n",
      "Right Knee     : x=0.383, y=0.708, score=0.626 ✓\n",
      "Left Ankle     : x=0.485, y=0.829, score=0.595 ✓\n",
      "Right Ankle    : x=0.410, y=0.894, score=0.804 ✓\n"
     ]
    }
   ],
   "source": [
    "## Check Keypoints & Conf. Score from Data ##\n",
    "\n",
    "# Set directory path\n",
    "image_path = \"../Ignore/Ruku/hasil/data_frame/frame_1.jpg\"\n",
    "\n",
    "# Load the input image.\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image)\n",
    "\n",
    "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "input_image = tf.expand_dims(image, axis=0)\n",
    "input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "keypoints_with_scores = movenet(input_image)\n",
    "# keypoints_with_scores = normalize_hip_center(load_movenet(input_image))\n",
    "\n",
    "# List name of 17 keypoints movenet\n",
    "keypoint_names = [\n",
    "    \"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\",\n",
    "    \"Left Shoulder\", \"Right Shoulder\", \"Left Elbow\", \"Right Elbow\",\n",
    "    \"Left Wrist\", \"Right Wrist\", \"Left Hip\", \"Right Hip\",\n",
    "    \"Left Knee\", \"Right Knee\", \"Left Ankle\", \"Right Ankle\"\n",
    "]\n",
    "\n",
    "# Get all keypoints\n",
    "keypoints = keypoints_with_scores[0, 0]  # shape (17, 3)\n",
    "print(keypoints_with_scores[0][0][11])\n",
    "\n",
    "# Threshold confidence\n",
    "threshold = 0.3\n",
    "\n",
    "# Iteration per keypoints print coordinate & conf. score\n",
    "for i, (y, x, score) in enumerate(keypoints):\n",
    "    name = keypoint_names[i]\n",
    "    status = \"✓\" if score > threshold else \"✗\"\n",
    "    print(f\"{name:<15}: x={x:.3f}, y={y:.3f}, score={score:.3f} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.28529868 0.5275587  0.6384971 ]\n",
      "   [0.26949152 0.5417508  0.65099037]\n",
      "   [0.27041304 0.51729876 0.48874363]\n",
      "   [0.2624041  0.57732856 0.46365488]\n",
      "   [0.26695392 0.5179516  0.2806773 ]\n",
      "   [0.32887143 0.6162292  0.6955754 ]\n",
      "   [0.31991145 0.50246346 0.5138745 ]\n",
      "   [0.4214181  0.64734155 0.5669779 ]\n",
      "   [0.4051485  0.4754783  0.5738289 ]\n",
      "   [0.41627938 0.5615572  0.337512  ]\n",
      "   [0.41382492 0.5063348  0.5347797 ]\n",
      "   [0.50848407 0.5913092  0.576711  ]\n",
      "   [0.5045647  0.52559865 0.63219327]\n",
      "   [0.60809153 0.5962836  0.68666077]\n",
      "   [0.60338867 0.5400499  0.45355007]\n",
      "   [0.70923615 0.59907556 0.5634635 ]\n",
      "   [0.69349104 0.5445759  0.5112442 ]]]]\n"
     ]
    }
   ],
   "source": [
    "## Visualize MoveNet Raw ##\n",
    "\n",
    "directory_path = \"Hizkia/Hasil/data_frame/Berdiri\"\n",
    "final_path = \"../Ignore/TES/frame_50.jpg\"\n",
    "image_path = directory_path+\"/frame_50.jpg\"\n",
    "\n",
    "print(load_movenet(image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
