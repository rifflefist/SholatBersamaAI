{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-hub in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow-hub) (2.1.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow-hub) (5.29.3)\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: tensorflow<2.20,>=2.19 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.17.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (1.70.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.13.0)\n",
      "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.5.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (14.0.0)\n",
      "Requirement already satisfied: namex in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (3.10.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (4.58.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\lvcm3\\AppData\\Local\\Temp\\pip-req-build-guut5bit'\n",
      "  error: RPC failed; curl 56 Recv failure: Connection was reset\n",
      "  error: 8822 bytes of body are still expected\n",
      "  fetch-pack: unexpected disconnect while reading sideband packet\n",
      "  fatal: early EOF\n",
      "  fatal: fetch-pack: invalid index-pack output\n",
      "  fatal: could not fetch 3ae87b238e001dd59d042826be8ce7b3c44fbfbd from promisor remote\n",
      "  warning: Clone succeeded, but checkout failed.\n",
      "  You can inspect what was checked out with 'git status'\n",
      "  and retry with 'git restore --source=HEAD :/'\n",
      "\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\lvcm3\\AppData\\Local\\Temp\\pip-req-build-guut5bit' did not run successfully.\n",
      "  │ exit code: 128\n",
      "  ╰─> See above for output.\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "× git clone --filter=blob:none --quiet https://github.com/tensorflow/docs 'C:\\Users\\lvcm3\\AppData\\Local\\Temp\\pip-req-build-guut5bit' did not run successfully.\n",
      "│ exit code: 128\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tensorflow/docs\n",
      "  Cloning https://github.com/tensorflow/docs to c:\\users\\lvcm3\\appdata\\local\\temp\\pip-req-build-guut5bit\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow-hub\n",
    "%pip install git+https://github.com/tensorflow/docs\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imageio in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (2.37.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from imageio) (2.1.3)\n",
      "Requirement already satisfied: pillow>=8.3.2 in c:\\users\\lvcm3\\anaconda3\\envs\\deim\\lib\\site-packages (from imageio) (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Import matplotlib libraries\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.collections import LineCollection\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython.display import HTML, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary that maps from joint names to keypoint indices.\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'left_eye': 1,\n",
    "    'right_eye': 2,\n",
    "    'left_ear': 3,\n",
    "    'right_ear': 4,\n",
    "    'left_shoulder': 5,\n",
    "    'right_shoulder': 6,\n",
    "    'left_elbow': 7,\n",
    "    'right_elbow': 8,\n",
    "    'left_wrist': 9,\n",
    "    'right_wrist': 10,\n",
    "    'left_hip': 11,\n",
    "    'right_hip': 12,\n",
    "    'left_knee': 13,\n",
    "    'right_knee': 14,\n",
    "    'left_ankle': 15,\n",
    "    'right_ankle': 16\n",
    "}\n",
    "\n",
    "# Maps bones to a matplotlib color name.\n",
    "KEYPOINT_EDGE_INDS_TO_COLOR = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "def _keypoints_and_edges_for_display(keypoints_with_scores,\n",
    "                                     height,\n",
    "                                     width,\n",
    "                                     keypoint_threshold=0.11):\n",
    "  \"\"\"Returns high confidence keypoints and edges for visualization.\n",
    "\n",
    "  Args:\n",
    "    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n",
    "      the keypoint coordinates and scores returned from the MoveNet model.\n",
    "    height: height of the image in pixels.\n",
    "    width: width of the image in pixels.\n",
    "    keypoint_threshold: minimum confidence score for a keypoint to be\n",
    "      visualized.\n",
    "\n",
    "  Returns:\n",
    "    A (keypoints_xy, edges_xy, edge_colors) containing:\n",
    "      * the coordinates of all keypoints of all detected entities;\n",
    "      * the coordinates of all skeleton edges of all detected entities;\n",
    "      * the colors in which the edges should be plotted.\n",
    "  \"\"\"\n",
    "  keypoints_all = []\n",
    "  keypoint_edges_all = []\n",
    "  edge_colors = []\n",
    "  num_instances, _, _, _ = keypoints_with_scores.shape\n",
    "  for idx in range(num_instances):\n",
    "    kpts_x = keypoints_with_scores[0, idx, :, 1]\n",
    "    kpts_y = keypoints_with_scores[0, idx, :, 0]\n",
    "    kpts_scores = keypoints_with_scores[0, idx, :, 2]\n",
    "    kpts_absolute_xy = np.stack(\n",
    "        [width * np.array(kpts_x), height * np.array(kpts_y)], axis=-1)\n",
    "    kpts_above_thresh_absolute = kpts_absolute_xy[\n",
    "        kpts_scores > keypoint_threshold, :]\n",
    "    keypoints_all.append(kpts_above_thresh_absolute)\n",
    "\n",
    "    for edge_pair, color in KEYPOINT_EDGE_INDS_TO_COLOR.items():\n",
    "      if (kpts_scores[edge_pair[0]] > keypoint_threshold and\n",
    "          kpts_scores[edge_pair[1]] > keypoint_threshold):\n",
    "        x_start = kpts_absolute_xy[edge_pair[0], 0]\n",
    "        y_start = kpts_absolute_xy[edge_pair[0], 1]\n",
    "        x_end = kpts_absolute_xy[edge_pair[1], 0]\n",
    "        y_end = kpts_absolute_xy[edge_pair[1], 1]\n",
    "        line_seg = np.array([[x_start, y_start], [x_end, y_end]])\n",
    "        keypoint_edges_all.append(line_seg)\n",
    "        edge_colors.append(color)\n",
    "  if keypoints_all:\n",
    "    keypoints_xy = np.concatenate(keypoints_all, axis=0)\n",
    "  else:\n",
    "    keypoints_xy = np.zeros((0, 17, 2))\n",
    "\n",
    "  if keypoint_edges_all:\n",
    "    edges_xy = np.stack(keypoint_edges_all, axis=0)\n",
    "  else:\n",
    "    edges_xy = np.zeros((0, 2, 2))\n",
    "  return keypoints_xy, edges_xy, edge_colors\n",
    "\n",
    "\n",
    "def draw_prediction_on_image(\n",
    "    image, keypoints_with_scores, crop_region=None, close_figure=False,\n",
    "    output_image_height=None):\n",
    "  \"\"\"Draws the keypoint predictions on image.\n",
    "\n",
    "  Args:\n",
    "    image: A numpy array with shape [height, width, channel] representing the\n",
    "      pixel values of the input image.\n",
    "    keypoints_with_scores: A numpy array with shape [1, 1, 17, 3] representing\n",
    "      the keypoint coordinates and scores returned from the MoveNet model.\n",
    "    crop_region: A dictionary that defines the coordinates of the bounding box\n",
    "      of the crop region in normalized coordinates (see the init_crop_region\n",
    "      function below for more detail). If provided, this function will also\n",
    "      draw the bounding box on the image.\n",
    "    output_image_height: An integer indicating the height of the output image.\n",
    "      Note that the image aspect ratio will be the same as the input image.\n",
    "\n",
    "  Returns:\n",
    "    A numpy array with shape [out_height, out_width, channel] representing the\n",
    "    image overlaid with keypoint predictions.\n",
    "  \"\"\"\n",
    "  height, width, channel = image.shape\n",
    "  aspect_ratio = float(width) / height\n",
    "  fig, ax = plt.subplots(figsize=(12 * aspect_ratio, 12))\n",
    "  # To remove the huge white borders\n",
    "  fig.tight_layout(pad=0)\n",
    "  ax.margins(0)\n",
    "  ax.set_yticklabels([])\n",
    "  ax.set_xticklabels([])\n",
    "  plt.axis('off')\n",
    "\n",
    "  im = ax.imshow(image)\n",
    "  line_segments = LineCollection([], linewidths=(4), linestyle='solid')\n",
    "  ax.add_collection(line_segments)\n",
    "  # Turn off tick labels\n",
    "  scat = ax.scatter([], [], s=60, color='#FF1493', zorder=3)\n",
    "\n",
    "  (keypoint_locs, keypoint_edges,\n",
    "   edge_colors) = _keypoints_and_edges_for_display(\n",
    "       keypoints_with_scores, height, width)\n",
    "\n",
    "  line_segments.set_segments(keypoint_edges)\n",
    "  line_segments.set_color(edge_colors)\n",
    "  if keypoint_edges.shape[0]:\n",
    "    line_segments.set_segments(keypoint_edges)\n",
    "    line_segments.set_color(edge_colors)\n",
    "  if keypoint_locs.shape[0]:\n",
    "    scat.set_offsets(keypoint_locs)\n",
    "\n",
    "  if crop_region is not None:\n",
    "    xmin = max(crop_region['x_min'] * width, 0.0)\n",
    "    ymin = max(crop_region['y_min'] * height, 0.0)\n",
    "    rec_width = min(crop_region['x_max'], 0.99) * width - xmin\n",
    "    rec_height = min(crop_region['y_max'], 0.99) * height - ymin\n",
    "    rect = patches.Rectangle(\n",
    "        (xmin,ymin),rec_width,rec_height,\n",
    "        linewidth=1,edgecolor='b',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "  fig.canvas.draw()\n",
    "  image_from_plot = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "  image_from_plot = image_from_plot.reshape(\n",
    "      fig.canvas.get_width_height()[::-1] + (4,))\n",
    "  image_from_plot = image_from_plot[:, :, :3]\n",
    "  plt.close(fig)\n",
    "  if output_image_height is not None:\n",
    "    output_image_width = int(output_image_height / height * width)\n",
    "    image_from_plot = cv2.resize(\n",
    "        image_from_plot, dsize=(output_image_width, output_image_height),\n",
    "         interpolation=cv2.INTER_CUBIC)\n",
    "  return image_from_plot\n",
    "\n",
    "def progress(value, max=100):\n",
    "  return HTML(\"\"\"\n",
    "      <progress\n",
    "          value='{value}'\n",
    "          max='{max}',\n",
    "          style='width: 100%'\n",
    "      >\n",
    "          {value}\n",
    "      </progress>\n",
    "  \"\"\".format(value=value, max=max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\lvcm3\\anaconda3\\envs\\deim\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_name = \"movenet_thunder\"\n",
    "\n",
    "if \"tflite\" in model_name:\n",
    "  if \"movenet_lightning_f16\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/float16/4?lite-format=tflite\n",
    "    input_size = 192\n",
    "  elif \"movenet_thunder_f16\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/float16/4?lite-format=tflite\n",
    "    input_size = 256\n",
    "  elif \"movenet_lightning_int8\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/lightning/tflite/int8/4?lite-format=tflite\n",
    "    input_size = 192\n",
    "  elif \"movenet_thunder_int8\" in model_name:\n",
    "    !wget -q -O model.tflite https://tfhub.dev/google/lite-model/movenet/singlepose/thunder/tflite/int8/4?lite-format=tflite\n",
    "    input_size = 256\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported model name: %s\" % model_name)\n",
    "\n",
    "  # Initialize the TFLite interpreter\n",
    "  interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\n",
    "  interpreter.allocate_tensors()\n",
    "\n",
    "  def movenet(input_image):\n",
    "    \"\"\"Runs detection on an input image.\n",
    "\n",
    "    Args:\n",
    "      input_image: A [1, height, width, 3] tensor represents the input image\n",
    "        pixels. Note that the height/width should already be resized and match the\n",
    "        expected input resolution of the model before passing into this function.\n",
    "\n",
    "    Returns:\n",
    "      A [1, 1, 17, 3] float numpy array representing the predicted keypoint\n",
    "      coordinates and scores.\n",
    "    \"\"\"\n",
    "    # TF Lite format expects tensor type of uint8.\n",
    "    input_image = tf.cast(input_image, dtype=tf.uint8)\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    interpreter.set_tensor(input_details[0]['index'], input_image.numpy())\n",
    "    # Invoke inference.\n",
    "    interpreter.invoke()\n",
    "    # Get the model prediction.\n",
    "    keypoints_with_scores = interpreter.get_tensor(output_details[0]['index'])\n",
    "    return keypoints_with_scores\n",
    "\n",
    "else:\n",
    "  if \"movenet_lightning\" in model_name:\n",
    "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/lightning/4\")\n",
    "    input_size = 192\n",
    "  elif \"movenet_thunder\" in model_name:\n",
    "    module = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "    input_size = 256\n",
    "  else:\n",
    "    raise ValueError(\"Unsupported model name: %s\" % model_name)\n",
    "\n",
    "  def movenet(input_image):\n",
    "    \"\"\"Runs detection on an input image.\n",
    "\n",
    "    Args:\n",
    "      input_image: A [1, height, width, 3] tensor represents the input image\n",
    "        pixels. Note that the height/width should already be resized and match the\n",
    "        expected input resolution of the model before passing into this function.\n",
    "\n",
    "    Returns:\n",
    "      A [1, 1, 17, 3] float numpy array representing the predicted keypoint\n",
    "      coordinates and scores.\n",
    "    \"\"\"\n",
    "    model = module.signatures['serving_default']\n",
    "\n",
    "    # SavedModel format expects tensor type of int32.\n",
    "    input_image = tf.cast(input_image, dtype=tf.int32)\n",
    "    # Run model inference.\n",
    "    outputs = model(input_image)\n",
    "    # Output is a [1, 1, 17, 3] tensor.\n",
    "    keypoints_with_scores = outputs['output_0'].numpy()\n",
    "    return keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_movenet(image_path):\n",
    "    # Load the input image.\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "\n",
    "    # Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "    input_image = tf.expand_dims(image, axis=0)\n",
    "    input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "\n",
    "    # Run model inference.\n",
    "    keypoints_with_scores = movenet(input_image)\n",
    "    \n",
    "    return keypoints_with_scores\n",
    "\n",
    "def visualize_movenet(keypoints_with_scores, image_path,  output_path):\n",
    "    \n",
    "    # Load the input image.\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    \n",
    "    # Visualize the predictions with image.\n",
    "    display_image = tf.expand_dims(image, axis=0)\n",
    "    display_image = tf.cast(tf.image.resize_with_pad(\n",
    "        display_image, 1280, 1280), dtype=tf.int32)\n",
    "    output_overlay = draw_prediction_on_image(\n",
    "        np.squeeze(display_image.numpy(), axis=0), keypoints_with_scores)\n",
    "\n",
    "    # plt.figure(figsize=(5, 5))\n",
    "    # plt.imshow(output_overlay)\n",
    "    # _ = plt.axis('off')\n",
    "\n",
    "    # Save the overlay\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(output_overlay, cv2.COLOR_RGB2BGR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_hip_center(keypoints_with_scores):\n",
    "    \n",
    "    # Get all keypoints\n",
    "    keypoints = keypoints_with_scores[0, 0, :, :2]  # shape: (17, 2)\n",
    "    scores = keypoints_with_scores[0, 0, :, 2]      # Confidence scores\n",
    "    \n",
    "    confidence_threshold = 0.11\n",
    "    \n",
    "    # Get center of body (hip)\n",
    "    left_hip = keypoints[11]\n",
    "    right_hip = keypoints[12]\n",
    "    \n",
    "    # Get the hip center (if confidence > threshold)\n",
    "    if scores[11] > confidence_threshold and scores[12] > confidence_threshold :\n",
    "        hip_center = (left_hip + right_hip) / 2\n",
    "    elif scores[11] > confidence_threshold:\n",
    "        hip_center = left_hip\n",
    "    elif scores[12] > confidence_threshold:\n",
    "        hip_center = right_hip\n",
    "    else:\n",
    "        # Fallback: use the mean of all the keypoints\n",
    "        valid_indices = np.where(scores > confidence_threshold)[0]\n",
    "        hip_center = np.mean(keypoints[valid_indices], axis=0) if len(valid_indices) > 0 else np.zeros(2)\n",
    "    \n",
    "    # Change the keypoints to hip oriented\n",
    "    keypoints_centered = keypoints - hip_center\n",
    "    \n",
    "    # Height estimation from shoulder to hip\n",
    "    left_shoulder = keypoints[5]\n",
    "    right_shoulder = keypoints[6]\n",
    "    \n",
    "    # Normalization with height estimation (if confidence > threshold)\n",
    "    if scores[5] > confidence_threshold and scores[6] > confidence_threshold and np.linalg.norm(left_shoulder - right_shoulder) > 0:\n",
    "        shoulder_center = (left_shoulder + right_shoulder) / 2\n",
    "        body_height = np.linalg.norm(shoulder_center - hip_center)\n",
    "        keypoints_normalized = keypoints_centered / body_height\n",
    "    else:\n",
    "        # Fallback: use a normal case body_height shoulder-to-hip 0.15 - 0.19\n",
    "        keypoints_normalized = keypoints_centered / 0.17\n",
    "    \n",
    "    return keypoints_normalized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From this, the code get started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize MoveNet\n",
    "\n",
    "Get all 3 movement (Berdiri, Sujud, Duduk)</br>\n",
    "**_<span style=\"color:cyan\">movement = [\"Berdiri\", \"Sujud\", \"Duduk\"]</span>_**\n",
    "\n",
    "Iteration per movement </br>\n",
    "**_<span style=\"color:cyan\">for j in movement:</span>_**\n",
    "\n",
    "Get data from directory path </br>\n",
    "**_<span style=\"color:cyan\">files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]</span>_**\n",
    "\n",
    "Iteration per data from directory </br>\n",
    "**_<span style=\"color:cyan\">for i, file in enumerate(files, start=1):</span>_**\n",
    "\n",
    "Run MoveNet to save to image </br>\n",
    "**_<span style=\"color:cyan\">visualize_movenet(load_movenet(image_path+str(i-1)+\".jpg\"), image_path+str(i-1)+\".jpg\", final_path+str(i-1)+\".jpg\")</span>_**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualize MoveNet Raw ##\n",
    "\n",
    "movement = [\"Berdiri\", \"Sujud\", \"Duduk\"]\n",
    "\n",
    "for j in movement:\n",
    "    # Set directory path\n",
    "    directory_path = \"Hasil/data_frame/\"+j\n",
    "    final_path = \"Hasil/final_frame/\"+j+\"/final_\"\n",
    "    image_path = directory_path+\"/frame_\"\n",
    "\n",
    "    # Get all total data in directory path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Iteration per data to movenet\n",
    "    for i, file in enumerate(files, start=1):\n",
    "        visualize_movenet(load_movenet(image_path+str(i-1)+\".jpg\"), image_path+str(i-1)+\".jpg\", final_path+str(i-1)+\".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Keypoints Save Fig Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalized Keypoints MoveNet Safe Plot ##\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "movement = [\"Berdiri\", \"Sujud\", \"Duduk\"]\n",
    "\n",
    "for j in range(len(movement)):\n",
    "    # Set directory path\n",
    "    directory_path = \"Hasil/data_frame/\"+movement[j]\n",
    "    final_path = \"Hasil/final1_frame/\"+movement[j]+\"/final_\"\n",
    "    image_path = directory_path+\"/frame_\"\n",
    "\n",
    "    # Get all total data in directory path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Iteration per data\n",
    "    for i, file in enumerate(files, start=1):\n",
    "\n",
    "        # Get keypoints after normalize from data in directory path\n",
    "        normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\"))\n",
    "\n",
    "        fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "        # Setting axis\n",
    "        ax.set_xlim(-2, 2)\n",
    "        ax.set_ylim(-2, 2)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.invert_yaxis()\n",
    "        ax.set_title(\"Normalized Pose\")\n",
    "\n",
    "        # Plot titik\n",
    "        for x, y in normalized_keypoints:\n",
    "            plt.plot(y, x, 'ro')  # titik merah\n",
    "\n",
    "        # Sambungkan titik-titik (opsional)\n",
    "        POSE_CONNECTIONS = [\n",
    "            (5, 6), (5, 11), (6, 12),  # shoulders to hips\n",
    "            (5, 7), (7, 9),  # left arm\n",
    "            (6, 8), (8, 10), # right arm\n",
    "            (11, 13), (13, 15),  # left leg\n",
    "            (12, 14), (14, 16),  # right leg\n",
    "            (11, 12), (5, 6)  # hips and shoulders\n",
    "        ]\n",
    "        for a, b in POSE_CONNECTIONS:\n",
    "            x1, y1 = normalized_keypoints[a]\n",
    "            x2, y2 = normalized_keypoints[b]\n",
    "            plt.plot([y1, y2], [x1, x2], 'b-')  # Blue line\n",
    "\n",
    "        # Keep margin\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{final_path}{i-1}.jpg\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized Keypoints to CSV\n",
    "\n",
    "Set Dictionary of keypoint</br>\n",
    "\n",
    "Set header of CSV</br>\n",
    "**<span style=\"color:cyan\">\n",
    "header = [] </br>\n",
    "for j in range(len(KEYPOINT_DICT)):</br>\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]</br>\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]</br>\n",
    "</span>**\n",
    "\n",
    "Open CSV file</br>\n",
    "**_<span style=\"color:cyan\">with open(file_output, mode='w', newline='') as file:</span>_**\n",
    "\n",
    "Get flatten keypoints normalize</br>\n",
    "**_<span style=\"color:cyan\">normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\")).flatten()</span>_**\n",
    "\n",
    "Write header & data</br>\n",
    "**_<span style=\"color:cyan\">writer.writerow([h.ljust(column_width) for h in header])</span>_**</br>\n",
    "**_<span style=\"color:cyan\">writer.writerow([h.ljust(column_width) for h in result])</span>_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Normalized Keypoints to CSV ##\n",
    "\n",
    "import csv\n",
    "\n",
    "movement = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "for m in movement:\n",
    "\n",
    "    # Set directory path\n",
    "    directory_path = \"Hasil/data_frame/\"+m\n",
    "    image_path = directory_path+\"/frame_\"\n",
    "\n",
    "    # Get all data from directory path\n",
    "    files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "    # Set header for CSV file\n",
    "    header = []\n",
    "\n",
    "    for j in range(len(KEYPOINT_DICT)):\n",
    "        header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]\n",
    "        header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]\n",
    "\n",
    "    file_output = \"Hasil/keypoints_\"+m+\".csv\"\n",
    "\n",
    "    # Fix width col\n",
    "    column_width = 12\n",
    "\n",
    "    # Open CSV file\n",
    "    with open(file_output, mode='w', newline='') as file:\n",
    "\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write CSV file header\n",
    "        writer.writerow([h.ljust(column_width) for h in header])\n",
    "\n",
    "        # Iteration per data in directory path\n",
    "        for i, file in enumerate(files, start=1):\n",
    "\n",
    "            # Get flatten normalize keypoints\n",
    "            normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\")).flatten()\n",
    "            result = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "\n",
    "            # Write CSV file data\n",
    "            writer.writerow([h.ljust(column_width) for h in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keypoints for Person to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save Normalized Keypoints to CSV ##\n",
    "\n",
    "import csv\n",
    "\n",
    "movement = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "person = [\"Galileo\", \"Hizkia\", \"Nicholas\", \"Ridwan\", \"Adji\", \"Bill\", \"Khanif\"]\n",
    "val = [\"Galileo\", \"Adji\"]\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "# Set header for CSV file\n",
    "header = []\n",
    "\n",
    "for j in range(len(KEYPOINT_DICT)):\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]\n",
    "header += [\"label\"]\n",
    "\n",
    "# Fix width col\n",
    "column_width = 12\n",
    "\n",
    "file_train = \"Hasil/keypoints_train.csv\"\n",
    "file_val = \"Hasil/keypoints_val.csv\"\n",
    "\n",
    "# Open CSV file\n",
    "with open(file_train, mode='w', newline='') as file:\n",
    "    with open(file_val, mode='w', newline='') as fileVal:\n",
    "\n",
    "        writer1 = csv.writer(fileVal)\n",
    "        writer = csv.writer(file)\n",
    "\n",
    "        # Write CSV file header\n",
    "        writer.writerow([h.ljust(column_width) for h in header])\n",
    "        writer1.writerow([h.ljust(column_width) for h in header])\n",
    "\n",
    "        writerTemp = writer\n",
    "\n",
    "        for p in person:\n",
    "\n",
    "            if p in val:\n",
    "                writerTemp = writer1\n",
    "            else:\n",
    "                writerTemp = writer\n",
    "\n",
    "            for m in movement:\n",
    "\n",
    "                # Set directory path\n",
    "                directory_path = p+\"/Hasil/data_frame/\"+m\n",
    "                image_path = directory_path+\"/frame_\"\n",
    "\n",
    "                # Get all data from directory path\n",
    "                files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "\n",
    "                # Iteration per data in directory path\n",
    "                for i, file in enumerate(files, start=1):\n",
    "\n",
    "                    # Get flatten normalize keypoints\n",
    "                    normalized_keypoints = normalize_hip_center(load_movenet(image_path+str(i-1)+\".jpg\")).flatten()\n",
    "                    result = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "                    result += [m]\n",
    "\n",
    "                    # Write CSV file data\n",
    "                    writerTemp.writerow([h.ljust(column_width) for h in result])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join All Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join Keypoints to Final Result\n",
    "\n",
    "import csv\n",
    "\n",
    "movement = [\"Berdiri\", \"Duduk\", \"Sujud\"]\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "final = \"Hasil/keypoints.csv\"\n",
    "\n",
    "with open(final, mode='w', newline='') as file :\n",
    "\n",
    "    header_bool = False\n",
    "    write_csv = csv.writer(file)\n",
    "\n",
    "    for i in range(len(movement)):\n",
    "\n",
    "        keypoints = \"Hasil/keypoints_\"+movement[i]+\".csv\"\n",
    "\n",
    "        with open(keypoints, mode='r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            header = next(reader)\n",
    "            header += [\"label\"]\n",
    "            if(not(header_bool)):\n",
    "                write_csv.writerow(header)\n",
    "                header_bool = True\n",
    "\n",
    "            for row in reader:\n",
    "                row = [float(rows) for rows in row]\n",
    "                row += [movement[i]]\n",
    "                write_csv.writerow(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Coordinate Real Image vs Augmented Image (Vertically Mirroring)\n",
    "\n",
    "#### Difference between real image & augmented (vertically mirroring) x & x' totally different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nose_y      ', 'nose_x      ', 'l_eye_y     ', 'l_eye_x     ', 'r_eye_y     ', 'r_eye_x     ', 'l_ear_y     ', 'l_ear_x     ', 'r_ear_y     ', 'r_ear_x     ', 'l_shldr_y   ', 'l_shldr_x   ', 'r_shldr_y   ', 'r_shldr_x   ', 'l_elbow_y   ', 'l_elbow_x   ', 'r_elbow_y   ', 'r_elbow_x   ', 'l_wrist_y   ', 'l_wrist_x   ', 'r_wrist_y   ', 'r_wrist_x   ', 'l_hip_y     ', 'l_hip_x     ', 'r_hip_y     ', 'r_hip_x     ', 'l_knee_y    ', 'l_knee_x    ', 'r_knee_y    ', 'r_knee_x    ', 'l_ankle_y   ', 'l_ankle_x   ', 'r_ankle_y   ', 'r_ankle_x   ']\n",
      "['557', '1.318346381 ', '-0.571944416', '1.377509236 ', '-0.605420411', '1.368300319 ', '-0.624004602', '1.280033827 ', '-0.621252596', '1.239267945 ', '-0.710023165', '0.889830530 ', '-0.508243859', '0.765324533 ', '-0.614459693', '0.883359194 ', '0.199855059 ', '0.841187477 ', '-0.239032492', '1.301983953 ', '0.123639010 ', '1.257931828 ', '0.102156200 ', '0.034755234 ', '-0.023501195', '-0.034755550', '0.023501195 ', '0.834784269 ', '0.198331967 ', '0.665311873 ', '0.185980454 ', '0.507609665 ', '0.311661482 ', '0.290738940 ', '0.360784113 ']\n",
      "['1342', '-1.099727988', '0.409966379 ', '-1.197170854', '0.494705498 ', '-1.193386078', '0.328392416 ', '-1.296021819', '0.494780779 ', '-1.305977464', '0.081380136 ', '-1.035103440', '0.481515527 ', '-0.944333255', '-0.195455164', '-0.335489661', '0.627446771 ', '-0.099193260', '-0.168618992', '0.249015003 ', '0.934208989 ', '0.519589186 ', '0.151498184 ', '-0.073964588', '0.271703154 ', '0.073964588 ', '-0.271703154', '0.610375822 ', '0.954915822 ', '0.547214568 ', '0.168938562 ', '0.559911728 ', '0.217740282 ', '0.694793463 ', '0.176104978 ']\n"
     ]
    }
   ],
   "source": [
    "## Check Difference Between Real Image & Augmented ##\n",
    "\n",
    "KEYPOINT_DICT = {\n",
    "    'nose': 0,\n",
    "    'l_eye': 1,\n",
    "    'r_eye': 2,\n",
    "    'l_ear': 3,\n",
    "    'r_ear': 4,\n",
    "    'l_shldr': 5,\n",
    "    'r_shldr': 6,\n",
    "    'l_elbow': 7,\n",
    "    'r_elbow': 8,\n",
    "    'l_wrist': 9,\n",
    "    'r_wrist': 10,\n",
    "    'l_hip': 11,\n",
    "    'r_hip': 12,\n",
    "    'l_knee': 13,\n",
    "    'r_knee': 14,\n",
    "    'l_ankle': 15,\n",
    "    'r_ankle': 16\n",
    "}\n",
    "\n",
    "# Set header to output\n",
    "header = []\n",
    "\n",
    "# Fix width col\n",
    "column_width = 12\n",
    "\n",
    "for j in range(0, 17):\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_y\"]\n",
    "    header += [next(k for k, v in KEYPOINT_DICT.items() if v == j)+\"_x\"]\n",
    "\n",
    "print([h.ljust(column_width) for h in header])\n",
    "\n",
    "## Value Check ##\n",
    "gerakan = \"Sujud\"\n",
    "frame = 557\n",
    "\n",
    "# Set directory path\n",
    "directory_path = \"Hasil/data_frame/\"+gerakan\n",
    "image_path = directory_path+\"/frame_\"\n",
    "\n",
    "# Get all data from directory path and total/2\n",
    "files = [f for f in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, f))]\n",
    "total_file = int(len(files)/2)\n",
    "\n",
    "# Image1 normal image get keypoints normalize\n",
    "image_path = \"Hasil/data_frame/\"+gerakan+\"/frame_\"+str(frame)+\".jpg\"\n",
    "normalized_keypoints = normalize_hip_center(load_movenet(image_path)).flatten()\n",
    "hasil = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "\n",
    "print([str(frame)]+[h.ljust(column_width) for h in hasil])\n",
    "\n",
    "# Image2 augmented image get keypoints normalize\n",
    "image_path = \"Hasil/data_frame/Duduk/frame_\"+str(frame+total_file)+\".jpg\"\n",
    "normalized_keypoints = normalize_hip_center(load_movenet(image_path)).flatten()\n",
    "hasil = [f\"{num:.9f}\" for num in normalized_keypoints]\n",
    "print([str(frame+total_file)]+[h.ljust(column_width) for h in hasil])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.71756077  0.968059  ]\n",
      " [ 0.8482476   0.99223155]\n",
      " [ 0.9050916   1.135846  ]\n",
      " [ 0.606267    1.1209421 ]\n",
      " [ 0.6210234   1.5625191 ]\n",
      " [-0.7001495   0.53740925]\n",
      " [-0.335894    1.1733255 ]\n",
      " [-0.74615765 -1.7703601 ]\n",
      " [-0.03977473  1.1125004 ]\n",
      " [ 0.8208825  -1.3322232 ]\n",
      " [ 0.2644343   1.7198913 ]\n",
      " [-1.975069   -0.01121307]\n",
      " [-1.8268708   0.17614509]\n",
      " [-0.80221087 -1.7228596 ]\n",
      " [-0.4721225  -0.6977344 ]\n",
      " [ 0.7342737  -1.3421639 ]\n",
      " [-2.4612463  -2.3448904 ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_path = \"Hasil/data_frame/Sujud/frame_1343.jpg\"\n",
    "normalized_keypoints = normalize_hip_center(load_movenet(image_path))\n",
    "\n",
    "print(normalized_keypoints)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5), dpi=100)\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "# Setting axis\n",
    "ax.set_xlim(-2, 2)\n",
    "ax.set_ylim(-2, 2)\n",
    "ax.set_aspect('equal')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title(\"Normalized Pose\")\n",
    "\n",
    "# Plot titik\n",
    "for x, y in normalized_keypoints:\n",
    "    plt.plot(y, x, 'ro')  # titik merah\n",
    "\n",
    "# Sambungkan titik-titik (opsional)\n",
    "POSE_CONNECTIONS = [\n",
    "    (5, 6), (5, 11), (6, 12),  # shoulders to hips\n",
    "    (5, 7), (7, 9),  # left arm\n",
    "    (6, 8), (8, 10), # right arm\n",
    "    (11, 13), (13, 15),  # left leg\n",
    "    (12, 14), (14, 16),  # right leg\n",
    "    (11, 12), (5, 6)  # hips and shoulders\n",
    "]\n",
    "for a, b in POSE_CONNECTIONS:\n",
    "    x1, y1 = normalized_keypoints[a]\n",
    "    x2, y2 = normalized_keypoints[b]\n",
    "    plt.plot([y1, y2], [x1, x2], 'b-')  # garis biru\n",
    "\n",
    "# Jaga margin tetap\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71722597 0.45903614 0.5398249 ]\n",
      "Nose           : x=0.479, y=0.573, score=0.622 ✓\n",
      "Left Eye       : x=0.491, y=0.559, score=0.640 ✓\n",
      "Right Eye      : x=0.468, y=0.559, score=0.532 ✓\n",
      "Left Ear       : x=0.490, y=0.548, score=0.359 ✓\n",
      "Right Ear      : x=0.432, y=0.543, score=0.720 ✓\n",
      "Left Shoulder  : x=0.488, y=0.583, score=0.561 ✓\n",
      "Right Shoulder : x=0.392, y=0.596, score=0.432 ✓\n",
      "Left Elbow     : x=0.510, y=0.680, score=0.353 ✓\n",
      "Right Elbow    : x=0.396, y=0.713, score=0.330 ✓\n",
      "Left Wrist     : x=0.553, y=0.764, score=0.389 ✓\n",
      "Right Wrist    : x=0.442, y=0.802, score=0.559 ✓\n",
      "Left Hip       : x=0.459, y=0.717, score=0.540 ✓\n",
      "Right Hip      : x=0.382, y=0.738, score=0.635 ✓\n",
      "Left Knee      : x=0.556, y=0.816, score=0.571 ✓\n",
      "Right Knee     : x=0.445, y=0.806, score=0.270 ✗\n",
      "Left Ankle     : x=0.451, y=0.808, score=0.136 ✗\n",
      "Right Ankle    : x=0.446, y=0.827, score=0.138 ✗\n"
     ]
    }
   ],
   "source": [
    "## Check Keypoints & Conf. Score from Data ##\n",
    "\n",
    "# Set directory path\n",
    "image_path = \"Hasil/data_frame/Duduk/frame_1343.jpg\"\n",
    "\n",
    "# Load the input image.\n",
    "image = tf.io.read_file(image_path)\n",
    "image = tf.image.decode_jpeg(image)\n",
    "\n",
    "# Resize and pad the image to keep the aspect ratio and fit the expected size.\n",
    "input_image = tf.expand_dims(image, axis=0)\n",
    "input_image = tf.image.resize_with_pad(input_image, input_size, input_size)\n",
    "keypoints_with_scores = movenet(input_image)\n",
    "# keypoints_with_scores = normalize_hip_center(load_movenet(input_image))\n",
    "\n",
    "# List name of 17 keypoints movenet\n",
    "keypoint_names = [\n",
    "    \"Nose\", \"Left Eye\", \"Right Eye\", \"Left Ear\", \"Right Ear\",\n",
    "    \"Left Shoulder\", \"Right Shoulder\", \"Left Elbow\", \"Right Elbow\",\n",
    "    \"Left Wrist\", \"Right Wrist\", \"Left Hip\", \"Right Hip\",\n",
    "    \"Left Knee\", \"Right Knee\", \"Left Ankle\", \"Right Ankle\"\n",
    "]\n",
    "\n",
    "# Get all keypoints\n",
    "keypoints = keypoints_with_scores[0, 0]  # shape (17, 3)\n",
    "print(keypoints_with_scores[0][0][11])\n",
    "\n",
    "# Threshold confidence\n",
    "threshold = 0.3\n",
    "\n",
    "# Iteration per keypoints print coordinate & conf. score\n",
    "for i, (y, x, score) in enumerate(keypoints):\n",
    "    name = keypoint_names[i]\n",
    "    status = \"✓\" if score > threshold else \"✗\"\n",
    "    print(f\"{name:<15}: x={x:.3f}, y={y:.3f}, score={score:.3f} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
